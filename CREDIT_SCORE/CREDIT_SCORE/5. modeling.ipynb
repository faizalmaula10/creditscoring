{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Modeling**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform:\n",
    "1. Forward Selection Procedure\n",
    "2. Best Model Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Perform Forward Selection Procedure**\n",
    "---\n",
    "Begin with null model (no predictors), then adds predictor that gives the greatest additional improvement to the model, one-at-a-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import library for modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load configuration\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/credit_risk_dataset.csv',\n",
       " 'dataset_path': 'data/output/data.pkl',\n",
       " 'predictors_set_path': 'data/output/predictors.pkl',\n",
       " 'response_set_path': 'data/output/response.pkl',\n",
       " 'train_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'test_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'data_train_path': 'data/output/data_train.pkl',\n",
       " 'data_train_binned_path': 'data/output/data_train_binned.pkl',\n",
       " 'crosstab_list_path': 'data/output/crosstab_list.pkl',\n",
       " 'WOE_table_path': 'data/output/WOE_table.pkl',\n",
       " 'IV_table_path': 'data/output/IV_table.pkl',\n",
       " 'WOE_map_dict_path': 'data/output/WOE_map_dict.pkl',\n",
       " 'X_train_woe_path': 'data/output/X_train_woe.pkl',\n",
       " 'response_variable': 'loan_status',\n",
       " 'test_size': 0.3,\n",
       " 'num_columns': ['person_age',\n",
       "  'person_income',\n",
       "  'person_emp_length',\n",
       "  'loan_amnt',\n",
       "  'loan_int_rate',\n",
       "  'loan_percent_income',\n",
       "  'cb_person_cred_hist_length'],\n",
       " 'cat_columns': ['person_home_ownership',\n",
       "  'loan_intent',\n",
       "  'loan_grade',\n",
       "  'cb_person_default_on_file'],\n",
       " 'missing_columns': ['person_emp_length_bin', 'loan_int_rate_bin'],\n",
       " 'num_of_bins': 4,\n",
       " 'num_of_cv': 10,\n",
       " 'scoring': 'recall',\n",
       " 'forward_models_path': 'models/forward_models.pkl',\n",
       " 'best_predictors_path': 'models/best_predictors_path.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_model_summary_path': 'models/best_model_summary.pkl'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function `forward()` to fit a model on the train set and calculate its CV score from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform forward selection procedure\n",
    "def forward(X, y, predictors, scoring='roc_auc', cv=5):\n",
    "    \"\"\"Function to perform forward selection procedure\"\"\"\n",
    "\n",
    "    # Define sample size and  number of all predictors\n",
    "    n_samples, n_predictors = X.shape\n",
    "\n",
    "    # Define list of all predictors\n",
    "    col_list = np.arange(n_predictors)\n",
    "\n",
    "    # Define remaining predictors for each k\n",
    "    remaining_predictors = [p for p in col_list if p not in predictors]\n",
    "\n",
    "    # Initialize list of predictors and its CV Score\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    # Cross validate each possible combination of remaining predictors\n",
    "    for p in remaining_predictors:\n",
    "        combi = predictors + [p]\n",
    "\n",
    "        # Extract predictors combination\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        # Define the estimator\n",
    "        model = LogisticRegression(penalty = None,\n",
    "                                   class_weight = 'balanced')\n",
    "\n",
    "        # Cross validate the recall scores of the model\n",
    "        cv_results = cross_validate(estimator = model,\n",
    "                                    X = X_,\n",
    "                                    y = y_,\n",
    "                                    scoring = scoring,\n",
    "                                    cv = cv)\n",
    "\n",
    "        # Calculate the average CV/recall score\n",
    "        score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "        # Append predictors combination and its CV Score to the list\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    # Tabulate the results\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                           \"CV Score\": score_list})\n",
    "\n",
    "    # Choose the best model\n",
    "    best_model = models.loc[models['CV Score'].argmax()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform forward selection on all characteristics\n",
    "def run_forward():\n",
    "    \"\"\"Function to perform forward selection on all characteristics\"\"\"\n",
    "\n",
    "    cv = CONFIG_DATA['num_of_cv']\n",
    "    scoring = CONFIG_DATA['scoring']\n",
    "\n",
    "    X_train_woe_path = CONFIG_DATA['X_train_woe_path']\n",
    "    X_train_woe = utils.pickle_load(X_train_woe_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = CONFIG_DATA['train_path'][1]\n",
    "    y_train = utils.pickle_load(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    # First, fit the null model\n",
    "    # Define predictor for the null model\n",
    "    predictor = []\n",
    "\n",
    "    # The predictor in the null model is zero values for all predictors\n",
    "    X_null = np.zeros((X_train.shape[0], 1))\n",
    "\n",
    "    # Define the estimator\n",
    "    model = LogisticRegression(penalty = None,\n",
    "                               class_weight = 'balanced')\n",
    "\n",
    "    # Cross validate\n",
    "    cv_results = cross_validate(estimator = model,\n",
    "                                X = X_null,\n",
    "                                y = y_train,\n",
    "                                cv = cv,\n",
    "                                scoring = scoring)\n",
    "\n",
    "    # Calculate the average CV score\n",
    "    score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "    # Create table for the best model of each k predictors\n",
    "    # Append the results of null model\n",
    "    forward_models = pd.DataFrame({\"Predictors\": [predictor],\n",
    "                                   \"CV Score\": [score_]})\n",
    "\n",
    "    # Next, perform forward selection for all predictors\n",
    "    # Define list of predictors\n",
    "    predictors = []\n",
    "    n_predictors = X_train.shape[1]\n",
    "\n",
    "    # Perform forward selection procedure for k=1,...,n_predictors\n",
    "    for k in range(n_predictors):\n",
    "        _, best_model = forward(X = X_train,\n",
    "                                y = y_train,\n",
    "                                predictors = predictors,\n",
    "                                scoring = scoring,\n",
    "                                cv = cv)\n",
    "\n",
    "        # Tabulate the best model of each k predictors\n",
    "        forward_models.loc[k+1] = best_model\n",
    "        predictors = best_model['Predictors']\n",
    "\n",
    "    # Find the best CV score\n",
    "    best_idx = forward_models['CV Score'].argmax()\n",
    "    best_cv_score = forward_models['CV Score'].loc[best_idx]\n",
    "    best_predictors = forward_models['Predictors'].loc[best_idx]\n",
    "\n",
    "    # Print the summary\n",
    "    print('===================================================')\n",
    "    print('Best index            :', best_idx)\n",
    "    print('Best CV Score         :', best_cv_score)\n",
    "    print('Best predictors (idx) :', best_predictors)\n",
    "    print('Best predictors       :')\n",
    "    print(X_train_woe.columns[best_predictors].tolist())\n",
    "    print('===================================================')\n",
    "\n",
    "    print(forward_models)\n",
    "    print('===================================================')\n",
    "    \n",
    "    forward_models_path = CONFIG_DATA['forward_models_path']\n",
    "    utils.pickle_dump(forward_models, forward_models_path)\n",
    "\n",
    "    best_predictors_path = CONFIG_DATA['best_predictors_path']\n",
    "    utils.pickle_dump(best_predictors, best_predictors_path)\n",
    "\n",
    "    return forward_models, best_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "Best index            : 2\n",
      "Best CV Score         : 0.8168803988590178\n",
      "Best predictors (idx) : [2, 9]\n",
      "Best predictors       :\n",
      "['person_home_ownership', 'cb_person_default_on_file']\n",
      "===================================================\n",
      "                            Predictors  CV Score\n",
      "0                                   []  0.000000\n",
      "1                                  [2]  0.736680\n",
      "2                               [2, 9]  0.816880\n",
      "3                            [2, 9, 0]  0.816880\n",
      "4                        [2, 9, 0, 10]  0.816880\n",
      "5                     [2, 9, 0, 10, 3]  0.784115\n",
      "6                  [2, 9, 0, 10, 3, 7]  0.728643\n",
      "7               [2, 9, 0, 10, 3, 7, 1]  0.744121\n",
      "8            [2, 9, 0, 10, 3, 7, 1, 6]  0.766630\n",
      "9         [2, 9, 0, 10, 3, 7, 1, 6, 5]  0.781509\n",
      "10     [2, 9, 0, 10, 3, 7, 1, 6, 5, 8]  0.794778\n",
      "11  [2, 9, 0, 10, 3, 7, 1, 6, 5, 8, 4]  0.797193\n",
      "===================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            Predictors  CV Score\n",
       " 0                                   []  0.000000\n",
       " 1                                  [2]  0.736680\n",
       " 2                               [2, 9]  0.816880\n",
       " 3                            [2, 9, 0]  0.816880\n",
       " 4                        [2, 9, 0, 10]  0.816880\n",
       " 5                     [2, 9, 0, 10, 3]  0.784115\n",
       " 6                  [2, 9, 0, 10, 3, 7]  0.728643\n",
       " 7               [2, 9, 0, 10, 3, 7, 1]  0.744121\n",
       " 8            [2, 9, 0, 10, 3, 7, 1, 6]  0.766630\n",
       " 9         [2, 9, 0, 10, 3, 7, 1, 6, 5]  0.781509\n",
       " 10     [2, 9, 0, 10, 3, 7, 1, 6, 5, 8]  0.794778\n",
       " 11  [2, 9, 0, 10, 3, 7, 1, 6, 5, 8, 4]  0.797193,\n",
       " [2, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the function\n",
    "run_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit the best model on whole X_train\n",
    "def best_model_fitting(best_predictors):\n",
    "    \"\"\"Function to fit best model on whole X_train\"\"\"\n",
    "\n",
    "    X_train_path = CONFIG_DATA['X_train_woe_path']\n",
    "    X_train_woe = utils.pickle_load(X_train_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = CONFIG_DATA['train_path'][1]\n",
    "    y_train = utils.pickle_load(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    if best_predictors is None:\n",
    "        best_predictors_path = CONFIG_DATA['best_predictors_path']\n",
    "        best_predictors = utils.pickle_load(best_predictors_path)\n",
    "        print(f\"Best predictors index   :\", best_predictors)\n",
    "    else:\n",
    "        print(f\"[Adjusted] best predictors index   :\", best_predictors)\n",
    "\n",
    "    # Define X with best predictors\n",
    "    X_train_best = X_train[:, best_predictors]\n",
    "\n",
    "    # Fit best model\n",
    "    best_model = LogisticRegression(penalty = None,\n",
    "                                    class_weight = 'balanced')\n",
    "    best_model.fit(X_train_best, y_train)\n",
    "\n",
    "    print(best_model)\n",
    "\n",
    "    # Extract the best model' parameter estimates\n",
    "    best_model_intercept = pd.DataFrame({'Characteristic': 'Intercept',\n",
    "                                         'Estimate': best_model.intercept_})\n",
    "    \n",
    "    best_model_params = X_train_woe.columns[best_predictors].tolist()\n",
    "\n",
    "    best_model_coefs = pd.DataFrame({'Characteristic': best_model_params,\n",
    "                                     'Estimate': np.reshape(best_model.coef_, \n",
    "                                                            len(best_predictors))})\n",
    "\n",
    "    best_model_summary = pd.concat((best_model_intercept, best_model_coefs),\n",
    "                                   axis = 0,\n",
    "                                   ignore_index = True)\n",
    "    \n",
    "    print('===================================================')\n",
    "    print(best_model_summary)\n",
    "    \n",
    "    best_model_path = CONFIG_DATA['best_model_path']\n",
    "    utils.pickle_dump(best_model, best_model_path)\n",
    "\n",
    "    best_model_summary_path = CONFIG_DATA['best_model_summary_path']\n",
    "    utils.pickle_dump(best_model_summary, best_model_summary_path)\n",
    "\n",
    "    return best_model, best_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best predictors index   : [2, 9]\n",
      "LogisticRegression(class_weight='balanced', penalty=None)\n",
      "===================================================\n",
      "              Characteristic  Estimate\n",
      "0                  Intercept  0.000216\n",
      "1      person_home_ownership -0.996248\n",
      "2  cb_person_default_on_file -0.991864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced', penalty=None),\n",
       "               Characteristic  Estimate\n",
       " 0                  Intercept  0.000216\n",
       " 1      person_home_ownership -0.996248\n",
       " 2  cb_person_default_on_file -0.991864)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the function\n",
    "best_model_fitting(best_predictors = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best Model Adjustment**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scorecards with too few characteristics are generally unable to withstand the test of time:\n",
    "  - They are susceptible to minor changes in the applicant profile.\n",
    "  - A good adjudicator will never look at just two characteristics from an application form to make a decision.\n",
    "\n",
    "We will include all characteristics in the final model.\n",
    "  - From the independence test, all characteristics are not independent of the response variable (probability of default).\n",
    "  - Generally, a final scorecards consist of between 8 and 15 characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adjusted] best predictors index   : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(class_weight='balanced', penalty=None)\n",
      "===================================================\n",
      "                Characteristic  Estimate\n",
      "0                    Intercept -0.059463\n",
      "1                   person_age -0.057122\n",
      "2                person_income -0.977773\n",
      "3        person_home_ownership -0.749994\n",
      "4            person_emp_length -0.249803\n",
      "5                  loan_intent -1.252916\n",
      "6                   loan_grade -1.156946\n",
      "7                    loan_amnt -0.855171\n",
      "8                loan_int_rate  0.008703\n",
      "9          loan_percent_income -0.765774\n",
      "10   cb_person_default_on_file  0.017819\n",
      "11  cb_person_cred_hist_length -0.569405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced', penalty=None),\n",
       "                 Characteristic  Estimate\n",
       " 0                    Intercept -0.059463\n",
       " 1                   person_age -0.057122\n",
       " 2                person_income -0.977773\n",
       " 3        person_home_ownership -0.749994\n",
       " 4            person_emp_length -0.249803\n",
       " 5                  loan_intent -1.252916\n",
       " 6                   loan_grade -1.156946\n",
       " 7                    loan_amnt -0.855171\n",
       " 8                loan_int_rate  0.008703\n",
       " 9          loan_percent_income -0.765774\n",
       " 10   cb_person_default_on_file  0.017819\n",
       " 11  cb_person_cred_hist_length -0.569405)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust the best predictors\n",
    "best_model_fitting(best_predictors = np.arange(11).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
